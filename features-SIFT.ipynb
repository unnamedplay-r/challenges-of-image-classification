{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standards\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from IPython import display\n",
    "\n",
    "# Image Processing Libraries\n",
    "import cv2\n",
    "import skimage.feature as feature\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import CENSURE\n",
    "from skimage import data, color, exposure, filters\n",
    "\n",
    "# Feature Extractions\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.feature_extraction.image import reconstruct_from_patches_2d\n",
    "\n",
    "rseed=4444\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_img = pd.read_pickle('df_img.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seeImg(img):\n",
    "    plt.imshow(img, aspect='auto')\n",
    "    plt.grid(False)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['indx', 'label', 'point', 'size', 'angle', 'response', 'octave', 'class_id']\n",
    "ft_cols = ['indx', 'label']\n",
    "dtypes =  {'indx': 'int', \n",
    "           'label': 'object',\n",
    "           'point': 'object',\n",
    "           'size': 'float',\n",
    "           'angle': 'float',\n",
    "           'response': 'float',\n",
    "           'octave': 'float',\n",
    "           'class_id': 'int'}\n",
    "\n",
    "ft_dtypes =  {'indx': 'int', \n",
    "              'label': 'object'}\n",
    "\n",
    "for x in range(0,128):\n",
    "    colname = 'des_'+str(x+1)\n",
    "    columns.append(colname)\n",
    "    ft_cols.append(colname)\n",
    "    dtypes[colname] = 'int16'\n",
    "    ft_dtypes[colname] = 'int16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sift_features = pd.DataFrame(columns=ft_cols)\n",
    "df_sift_features = df_sift_features.astype(ft_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawSift(img, kp):\n",
    "    sift_img=cv2.drawKeypoints(img,kp,img)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(sift_img)\n",
    "    # descs_num = descs.shape[0] * descs.shape[1]\n",
    "    # ax.set_title('%i DAISY descriptors extracted:' % descs_num)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.system('afplay /System/Library/Sounds/Sosumi.aiff')\n",
    "os.system('say \"Complete\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cutest tree ever: images[1400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "# number of clusters / size of 'image model' / size of histogram\n",
    "d = 500\n",
    "kmeans = MiniBatchKMeans(n_clusters=d, random_state=rseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets= ['ak47', 'american-flag', 'backpack', 'baseball-bat',\n",
    "          'baseball-glove', 'basketball-hoop', 'bat', 'bathtub', 'bear',\n",
    "          'beer-mug', 'billiards', 'binoculars', 'birdbath', 'blimp',\n",
    "          'bonsai', 'boom-box', 'bowling-ball', 'bowling-pin', 'boxing-glove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sift_chunks = pd.read_csv('sift_features_resized.csv',\n",
    "                             header=None,\n",
    "                             names=columns,\n",
    "                             iterator=True,\n",
    "                             chunksize=2000,\n",
    "                             dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current index: 876000\n",
      "brain\n",
      "Any true? False\n",
      "Breaking!\n"
     ]
    }
   ],
   "source": [
    "# KMeans Clustering\n",
    "for features in df_sift_chunks:\n",
    "    print('Current index:', features.index[0])\n",
    "    print(features.label.values[0])\n",
    "    \n",
    "    chk_lbl = features.label.isin(targets)\n",
    "    features = features[chk_lbl]\n",
    "    \n",
    "    print('Any true?',chk_lbl.any())\n",
    "    \n",
    "    if chk_lbl.any():\n",
    "        kmeans.partial_fit(features.iloc[:,8:])\n",
    "        display.clear_output(wait=True)\n",
    "    else:\n",
    "        print('Breaking!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./pkls/sift_kmeans_500.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current index: 876000\n",
      "Current Label: brain \n",
      "\n",
      "Breaking!\n"
     ]
    }
   ],
   "source": [
    "for features in df_sift_chunks:\n",
    "    print('Current index:', features.index[0])\n",
    "    print('Current Label:',features.label.values[0],'\\n')\n",
    "    \n",
    "    chk_lbl = features.label.isin(targets)\n",
    "    features = features[chk_lbl]\n",
    "    \n",
    "    if chk_lbl.any():\n",
    "        features['cluster'] = (features\n",
    "                                .apply(lambda x: pd.Series(kmeans.predict(x.iloc[8:].values.reshape(1,-1))),\n",
    "                                       axis=1))\n",
    "\n",
    "        df = (features\n",
    "              .groupby(['label','indx'])['cluster']\n",
    "              .apply(lambda x: np.histogram(x, bins=range(0,d))[0])\n",
    "              .reset_index()\n",
    "              .rename(columns={'cluster': 'des'}))\n",
    "    #     print('Dataframe:\\n\\n',df)\n",
    "\n",
    "        des = df['des'].apply(pd.Series)\n",
    "        des = des.rename(columns = lambda x: 'des_' + str(x))\n",
    "    #     print('\\nDesc:\\n\\n',desc)\n",
    "\n",
    "        df = pd.concat([df[:], des[:]], axis=1, join='inner')\n",
    "        df = df.drop(['des'], axis=1)\n",
    "    #     print('\\nDataframe:\\n\\n',df)\n",
    "\n",
    "        df_sift_features = pd.concat([df_sift_features, df])\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "    else:\n",
    "        print('Breaking!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sift_features = df_sift_features.reset_index()\n",
    "df_sift_features = df_sift_features.drop(['index'], axis=1)\n",
    "df_sift_features = (df_sift_features\n",
    "                     .groupby(['label','indx'])\n",
    "                     .sum()\n",
    "                     .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./pkls/df_sift_features500.pkl', 'wb') as f:\n",
    "    pickle.dump(df_sift_features, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
